Thoughts:
	- we don't really care about graph completeness
		- if it's not reachable from the roots, its dead
	- even though potential race conditions exist in shared memory
		implementations, we are safe to ignore
		- all writes during a Marking phase are the setting of a flag
		- two interleaved settings of a flag result in the flag being set

Techniques discussed for marking:

	Sequential

		Basic technique. Recursively traverse graph.

	MPI
		Static Task Assignment

			This technique divides rootset evenly between slots. Each slot is in
			charge of marking a subset of the roots. Master slot combines sub-results
			(essentially ANDing each result array)

			Cons:
				- Entire graph is copied to each slot.
				- Work is not necessarily balanced (one root might reach much more than
					another)
				- Duplication of work (sub-graph may be reachable from more than one
					root)

		Dynamic Task Assignment (root grainularity)

			Each slot is initially given one root to mark. Upon completion, it
			receives another. This continues until all roots are marked.

			Cons:
				- Entire graph is copied to each slot.
				- Although better, work still may not be balanced
				- Again, duplication of work
			
		DTA (predefined # of marks)

			Each slot is initially given one root to mark. It marks a predefined
			number of nodes, and then all immediately reachable children (if any) are
			added to the rootset. Results are aggregrated by the master node, and
			process continues until rootset is empty.

			Pros:
				- Minimizes duplication of effort
				- Work is balanced to grainularity of task size

			Cons:
				- Entire graph is copied to each slot

		Work Stealing

			Roots are divided evenly between slots. If a slot runs out, it attempts to
			steal work from another slot (acquire a node to begin marking from).

			Pros:
				- work is essentially balanced with minimal communication implications

			Cons:
				- Entire graph is copied to each slot

	OpenMP
		Static Task Assignment
		
			Each thread marks a static subset of roots. As mentioned above, even
			though the potential for contention to exist between collector threads, we
			can safely ignore as the semantics are unaffected.

			Pros:
				- Minimizes the cost of communication

			Cons:
				- balancing
					- runtime is bounded by the root with the largest reach

	CUDA (GPU techniques)
		Propogation
			
			A GPU thread is created for every node of the graph. At time step 1, each
			root of the rootset is notified to mark itself. At time step 2, all
			children of all roots are notified to mark themselves... This technique
			propagates across the entire graph.

			Pros:
				- fast, O(<breadth of graph>)

			Cons:
				- Entire graph is copied to each slot
